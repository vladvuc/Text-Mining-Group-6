{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\Documents\\GitHub\\Text-Mining-Group-6\\lab1\\Lab1-apple-samsung-example.txt\n",
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print(path_to_file)\n",
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1142\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Adam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "# nltk.download()\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = []\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_id = 1\n",
    "print('SENTENCE', sentences_nltk[sent_id])\n",
    "print('TOKENS', tokens_per_sentence[sent_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_per_sentence = []\n",
    "for tokens in tokens_per_sentence:\n",
    "    pos_tags_per_sentence.append(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]\n",
      "\n",
      "Sentence 1: [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]\n",
      "\n",
      "Sentence 2: [('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('â€œacted', 'VBN'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")]\n",
      "\n",
      "Sentence 3: [('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('Â£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]\n",
      "\n",
      "Sentence 4: [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]\n",
      "\n",
      "Sentence 5: [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pos_tags in enumerate(pos_tags_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(pos_tags)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')], [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')], [('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('â€œacted', 'VBN'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")], [('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('Â£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')], [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')], [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_per_sentence = []\n",
    "for tagged_sentence in pos_tags_per_sentence:\n",
    "    ner_tags_per_sentence.append(nltk.chunk.ne_chunk(tagged_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: (S\n",
      "  https/NN\n",
      "  :/:\n",
      "  //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ\n",
      "  Documents/NNS\n",
      "  filed/VBN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  (ORGANIZATION San/NNP Jose/NNP)\n",
      "  federal/JJ\n",
      "  court/NN\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  on/IN\n",
      "  November/NNP\n",
      "  23/CD\n",
      "  list/NN\n",
      "  six/CD\n",
      "  (ORGANIZATION Samsung/NNP)\n",
      "  products/NNS\n",
      "  running/VBG\n",
      "  the/DT\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  (GPE Bean/NNP)\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  Ice/NNP\n",
      "  Cream/NNP\n",
      "  Sandwich/NNP\n",
      "  ''/''\n",
      "  operating/VBG\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (PERSON Apple/NNP)\n",
      "  claims/VBZ\n",
      "  infringe/VB\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 1: (S\n",
      "  The/DT\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  affected/VBN\n",
      "  are/VBP\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  ,/,\n",
      "  running/VBG\n",
      "  the/DT\n",
      "  new/JJ\n",
      "  (PERSON Jelly/NNP Bean/NNP)\n",
      "  system/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  Tab/NNP\n",
      "  8.9/CD\n",
      "  Wifi/NNP\n",
      "  tablet/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  Tab/NNP\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  (PERSON Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "  and/CC\n",
      "  (PERSON Galaxy/NNP S/NNP)\n",
      "  III/NNP\n",
      "  mini/NN\n",
      "  ./.)\n",
      "\n",
      "Sentence 2: (S\n",
      "  (PERSON Apple/NNP)\n",
      "  stated/VBD\n",
      "  it/PRP\n",
      "  had/VBD\n",
      "  â€œacted/VBN\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  in/IN\n",
      "  order/NN\n",
      "  to/TO\n",
      "  ``/``\n",
      "  determine/VB\n",
      "  that/IN\n",
      "  these/DT\n",
      "  newly/RB\n",
      "  released/VBN\n",
      "  products/NNS\n",
      "  do/VBP\n",
      "  infringe/VB\n",
      "  many/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  asserted/VBN\n",
      "  by/IN\n",
      "  (PERSON Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "Sentence 3: (S\n",
      "  In/IN\n",
      "  (GPE August/NNP)\n",
      "  ,/,\n",
      "  (PERSON Samsung/NNP)\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  (GSP US/NNP)\n",
      "  patent/NN\n",
      "  case/NN\n",
      "  to/TO\n",
      "  (GPE Apple/NNP)\n",
      "  and/CC\n",
      "  was/VBD\n",
      "  ordered/VBN\n",
      "  to/TO\n",
      "  pay/VB\n",
      "  its/PRP$\n",
      "  rival/JJ\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  Â£0.66bn/NN\n",
      "  )/)\n",
      "  in/IN\n",
      "  damages/NNS\n",
      "  for/IN\n",
      "  copying/VBG\n",
      "  features/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION iPad/NN)\n",
      "  and/CC\n",
      "  (ORGANIZATION iPhone/NN)\n",
      "  in/IN\n",
      "  its/PRP$\n",
      "  (GPE Galaxy/NNP)\n",
      "  range/NN\n",
      "  of/IN\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 4: (S\n",
      "  (GPE Samsung/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  world/NN\n",
      "  's/POS\n",
      "  top/JJ\n",
      "  mobile/NN\n",
      "  phone/NN\n",
      "  maker/NN\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  appealing/VBG\n",
      "  the/DT\n",
      "  ruling/NN\n",
      "  ./.)\n",
      "\n",
      "Sentence 5: (S\n",
      "  A/DT\n",
      "  similar/JJ\n",
      "  case/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION UK/NNP)\n",
      "  found/VBD\n",
      "  in/IN\n",
      "  (GPE Samsung/NNP)\n",
      "  's/POS\n",
      "  favour/NN\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (PERSON Apple/NNP)\n",
      "  to/TO\n",
      "  publish/VB\n",
      "  an/DT\n",
      "  apology/NN\n",
      "  making/VBG\n",
      "  clear/JJ\n",
      "  that/IN\n",
      "  the/DT\n",
      "  (LOCATION South/JJ Korean/JJ)\n",
      "  firm/NN\n",
      "  had/VBD\n",
      "  not/RB\n",
      "  copied/VBN\n",
      "  its/PRP$\n",
      "  iPad/NN\n",
      "  when/WRB\n",
      "  designing/VBG\n",
      "  its/PRP$\n",
      "  own/JJ\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, ner_tags in enumerate(ner_tags_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(ner_tags)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_output_per_sentence = [constituent_parser.parse(pos_tags) for pos_tags in pos_tags_per_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: (S\n",
      "  (NP https/NN)\n",
      "  :/:\n",
      "  (NP\n",
      "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
      "  Documents/NNS\n",
      "  (VP (V filed/VBN))\n",
      "  to/TO\n",
      "  (NP the/DT)\n",
      "  San/NNP\n",
      "  Jose/NNP\n",
      "  (NP federal/JJ court/NN)\n",
      "  (P in/IN)\n",
      "  California/NNP\n",
      "  (P on/IN)\n",
      "  November/NNP\n",
      "  23/CD\n",
      "  (NP list/NN)\n",
      "  six/CD\n",
      "  Samsung/NNP\n",
      "  products/NNS\n",
      "  (VP (V running/VBG) (NP the/DT))\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  Bean/NNP\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  Ice/NNP\n",
      "  Cream/NNP\n",
      "  Sandwich/NNP\n",
      "  ''/''\n",
      "  (VP (V operating/VBG))\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  Apple/NNP\n",
      "  (VP (V claims/VBZ))\n",
      "  (VP (V infringe/VB))\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 1: (S\n",
      "  (NP The/DT)\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  (VP (V affected/VBN))\n",
      "  (VP (V are/VBP) (NP the/DT))\n",
      "  Galaxy/NNP\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  ,/,\n",
      "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
      "  Jelly/NNP\n",
      "  Bean/NNP\n",
      "  (NP system/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  Galaxy/NNP\n",
      "  Tab/NNP\n",
      "  8.9/CD\n",
      "  Wifi/NNP\n",
      "  (NP tablet/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  Galaxy/NNP\n",
      "  Tab/NNP\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  Galaxy/NNP\n",
      "  Rugby/NNP\n",
      "  Pro/NNP\n",
      "  and/CC\n",
      "  Galaxy/NNP\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  (NP mini/NN)\n",
      "  ./.)\n",
      "\n",
      "Sentence 2: (S\n",
      "  Apple/NNP\n",
      "  (VP (V stated/VBD))\n",
      "  it/PRP\n",
      "  (VP (V had/VBD))\n",
      "  (VP (V â€œacted/VBN))\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  (PP (P in/IN) (NP order/NN))\n",
      "  to/TO\n",
      "  ``/``\n",
      "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
      "  newly/RB\n",
      "  (VP (V released/VBN))\n",
      "  products/NNS\n",
      "  (VP (V do/VBP))\n",
      "  (VP\n",
      "    (V infringe/VB)\n",
      "    (NP many/JJ)\n",
      "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  (VP (V asserted/VBN))\n",
      "  (P by/IN)\n",
      "  Apple/NNP\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "Sentence 3: (S\n",
      "  (P In/IN)\n",
      "  August/NNP\n",
      "  ,/,\n",
      "  Samsung/NNP\n",
      "  (VP (V lost/VBD) (NP a/DT))\n",
      "  US/NNP\n",
      "  (NP patent/NN case/NN)\n",
      "  to/TO\n",
      "  Apple/NNP\n",
      "  and/CC\n",
      "  (VP (V was/VBD))\n",
      "  (VP (V ordered/VBN))\n",
      "  to/TO\n",
      "  (VP (V pay/VB))\n",
      "  its/PRP$\n",
      "  (NP rival/JJ)\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  (NP Â£0.66bn/NN)\n",
      "  )/)\n",
      "  (P in/IN)\n",
      "  damages/NNS\n",
      "  (P for/IN)\n",
      "  (VP (V copying/VBG))\n",
      "  features/NNS\n",
      "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
      "  and/CC\n",
      "  (NP iPhone/NN)\n",
      "  (P in/IN)\n",
      "  its/PRP$\n",
      "  Galaxy/NNP\n",
      "  (NP range/NN)\n",
      "  (P of/IN)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 4: (S\n",
      "  Samsung/NNP\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
      "  's/POS\n",
      "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
      "  ,/,\n",
      "  (VP (V is/VBZ))\n",
      "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
      "  ./.)\n",
      "\n",
      "Sentence 5: (S\n",
      "  (NP A/DT similar/JJ case/NN)\n",
      "  (PP (P in/IN) (NP the/DT))\n",
      "  UK/NNP\n",
      "  (VP (V found/VBD))\n",
      "  (P in/IN)\n",
      "  Samsung/NNP\n",
      "  's/POS\n",
      "  (NP favour/NN)\n",
      "  and/CC\n",
      "  (VP (V ordered/VBD))\n",
      "  Apple/NNP\n",
      "  to/TO\n",
      "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
      "  (VP\n",
      "    (V making/VBG)\n",
      "    (NP clear/JJ)\n",
      "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
      "  (VP (V had/VBD))\n",
      "  not/RB\n",
      "  (VP (V copied/VBN))\n",
      "  its/PRP$\n",
      "  (NP iPad/NN)\n",
      "  when/WRB\n",
      "  (VP (V designing/VBG))\n",
      "  its/PRP$\n",
      "  (NP own/JJ)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, cons_outputs in enumerate(constituency_output_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(cons_outputs)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {<NNP>*}       # Named Entity Phrases - Any # of NNPs in a row''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_v2_output_per_sentence = [constituent_parser_v2.parse(pos_tags) for pos_tags in pos_tags_per_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: (S\n",
      "  (NP https/NN)\n",
      "  :/:\n",
      "  (NP\n",
      "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
      "  Documents/NNS\n",
      "  (VP (V filed/VBN))\n",
      "  to/TO\n",
      "  (NP the/DT)\n",
      "  (NEP San/NNP Jose/NNP)\n",
      "  (NP federal/JJ court/NN)\n",
      "  (P in/IN)\n",
      "  (NEP California/NNP)\n",
      "  (P on/IN)\n",
      "  (NEP November/NNP)\n",
      "  23/CD\n",
      "  (NP list/NN)\n",
      "  six/CD\n",
      "  (NEP Samsung/NNP)\n",
      "  products/NNS\n",
      "  (VP (V running/VBG) (NP the/DT))\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  (NEP Bean/NNP)\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  (NEP Ice/NNP Cream/NNP Sandwich/NNP)\n",
      "  ''/''\n",
      "  (VP (V operating/VBG))\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (NEP Apple/NNP)\n",
      "  (VP (V claims/VBZ))\n",
      "  (VP (V infringe/VB))\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 1: (S\n",
      "  (NP The/DT)\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  (VP (V affected/VBN))\n",
      "  (VP (V are/VBP) (NP the/DT))\n",
      "  (NEP Galaxy/NNP S/NNP III/NNP)\n",
      "  ,/,\n",
      "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
      "  (NEP Jelly/NNP Bean/NNP)\n",
      "  (NP system/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  (NEP Galaxy/NNP Tab/NNP)\n",
      "  8.9/CD\n",
      "  (NEP Wifi/NNP)\n",
      "  (NP tablet/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  (NEP Galaxy/NNP Tab/NNP)\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  (NEP Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "  and/CC\n",
      "  (NEP Galaxy/NNP S/NNP III/NNP)\n",
      "  (NP mini/NN)\n",
      "  ./.)\n",
      "\n",
      "Sentence 2: (S\n",
      "  (NEP Apple/NNP)\n",
      "  (VP (V stated/VBD))\n",
      "  it/PRP\n",
      "  (VP (V had/VBD))\n",
      "  (VP (V â€œacted/VBN))\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  (PP (P in/IN) (NP order/NN))\n",
      "  to/TO\n",
      "  ``/``\n",
      "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
      "  newly/RB\n",
      "  (VP (V released/VBN))\n",
      "  products/NNS\n",
      "  (VP (V do/VBP))\n",
      "  (VP\n",
      "    (V infringe/VB)\n",
      "    (NP many/JJ)\n",
      "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  (VP (V asserted/VBN))\n",
      "  (P by/IN)\n",
      "  (NEP Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "Sentence 3: (S\n",
      "  (P In/IN)\n",
      "  (NEP August/NNP)\n",
      "  ,/,\n",
      "  (NEP Samsung/NNP)\n",
      "  (VP (V lost/VBD) (NP a/DT))\n",
      "  (NEP US/NNP)\n",
      "  (NP patent/NN case/NN)\n",
      "  to/TO\n",
      "  (NEP Apple/NNP)\n",
      "  and/CC\n",
      "  (VP (V was/VBD))\n",
      "  (VP (V ordered/VBN))\n",
      "  to/TO\n",
      "  (VP (V pay/VB))\n",
      "  its/PRP$\n",
      "  (NP rival/JJ)\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  (NP Â£0.66bn/NN)\n",
      "  )/)\n",
      "  (P in/IN)\n",
      "  damages/NNS\n",
      "  (P for/IN)\n",
      "  (VP (V copying/VBG))\n",
      "  features/NNS\n",
      "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
      "  and/CC\n",
      "  (NP iPhone/NN)\n",
      "  (P in/IN)\n",
      "  its/PRP$\n",
      "  (NEP Galaxy/NNP)\n",
      "  (NP range/NN)\n",
      "  (P of/IN)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 4: (S\n",
      "  (NEP Samsung/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
      "  's/POS\n",
      "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
      "  ,/,\n",
      "  (VP (V is/VBZ))\n",
      "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
      "  ./.)\n",
      "\n",
      "Sentence 5: (S\n",
      "  (NP A/DT similar/JJ case/NN)\n",
      "  (PP (P in/IN) (NP the/DT))\n",
      "  (NEP UK/NNP)\n",
      "  (VP (V found/VBD))\n",
      "  (P in/IN)\n",
      "  (NEP Samsung/NNP)\n",
      "  's/POS\n",
      "  (NP favour/NN)\n",
      "  and/CC\n",
      "  (VP (V ordered/VBD))\n",
      "  (NEP Apple/NNP)\n",
      "  to/TO\n",
      "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
      "  (VP\n",
      "    (V making/VBG)\n",
      "    (NP clear/JJ)\n",
      "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
      "  (VP (V had/VBD))\n",
      "  not/RB\n",
      "  (VP (V copied/VBN))\n",
      "  its/PRP$\n",
      "  (NP iPad/NN)\n",
      "  when/WRB\n",
      "  (VP (V designing/VBG))\n",
      "  its/PRP$\n",
      "  (NP own/JJ)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, cons_outputs in enumerate(constituency_v2_output_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(cons_outputs)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz (13.7 MB)\n",
      "     ---------------------------------------- 13.7/13.7 MB 8.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.17)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (63.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.23.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.64.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\adam\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\adam\\appdata\\roaming\\python\\python39\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html PROPN NNP\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "Documents NOUN NNS\n",
      "filed VERB VBN\n",
      "to ADP IN\n",
      "the DET DT\n",
      "San PROPN NNP\n",
      "Jose PROPN NNP\n",
      "federal ADJ JJ\n",
      "court NOUN NN\n",
      "in ADP IN\n",
      "California PROPN NNP\n",
      "on ADP IN\n",
      "November PROPN NNP\n",
      "23 NUM CD\n",
      "list NOUN NN\n",
      "six NUM CD\n",
      "Samsung PROPN NNP\n",
      "products NOUN NNS\n",
      "running VERB VBG\n",
      "the DET DT\n",
      "\" PUNCT ``\n",
      "Jelly PROPN NNP\n",
      "Bean PROPN NNP\n",
      "\" PUNCT ''\n",
      "and CCONJ CC\n",
      "\" PUNCT ``\n",
      "Ice PROPN NNP\n",
      "Cream PROPN NNP\n",
      "Sandwich PROPN NNP\n",
      "\" PUNCT ''\n",
      "operating NOUN NN\n",
      "systems NOUN NNS\n",
      ", PUNCT ,\n",
      "which DET WDT\n",
      "Apple PROPN NNP\n",
      "claims VERB VBZ\n",
      "infringe VERB VBP\n",
      "its PRON PRP$\n",
      "patents NOUN NNS\n",
      ". PUNCT .\n",
      "\n",
      " SPACE _SP\n",
      "The DET DT\n",
      "six NUM CD\n",
      "phones NOUN NNS\n",
      "and CCONJ CC\n",
      "tablets NOUN NNS\n",
      "affected VERB VBN\n",
      "are AUX VBP\n",
      "the DET DT\n",
      "Galaxy PROPN NNP\n",
      "S PROPN NNP\n",
      "III PROPN NNP\n",
      ", PUNCT ,\n",
      "running VERB VBG\n",
      "the DET DT\n",
      "new ADJ JJ\n",
      "Jelly PROPN NNP\n",
      "Bean PROPN NNP\n",
      "system NOUN NN\n",
      ", PUNCT ,\n",
      "the DET DT\n",
      "Galaxy PROPN NNP\n",
      "Tab PROPN NNP\n",
      "8.9 NUM CD\n",
      "Wifi PROPN NNP\n",
      "tablet NOUN NN\n",
      ", PUNCT ,\n",
      "the DET DT\n",
      "Galaxy PROPN NNP\n",
      "Tab PROPN NNP\n",
      "2 NUM CD\n",
      "10.1 NUM CD\n",
      ", PUNCT ,\n",
      "Galaxy PROPN NNP\n",
      "Rugby PROPN NNP\n",
      "Pro PROPN NNP\n",
      "and CCONJ CC\n",
      "Galaxy PROPN NNP\n",
      "S PROPN NNP\n",
      "III PROPN NNP\n",
      "mini NOUN NN\n",
      ". PUNCT .\n",
      "\n",
      " SPACE _SP\n",
      "Apple PROPN NNP\n",
      "stated VERB VBD\n",
      "it PRON PRP\n",
      "had AUX VBD\n",
      "â€œacted VERB VBN\n",
      "quickly ADV RB\n",
      "and CCONJ CC\n",
      "diligently ADV RB\n",
      "\" PUNCT ''\n",
      "in ADP IN\n",
      "order NOUN NN\n",
      "to PART TO\n",
      "\" PUNCT ``\n",
      "determine VERB VB\n",
      "that SCONJ IN\n",
      "these DET DT\n",
      "newly ADV RB\n",
      "released VERB VBN\n",
      "products NOUN NNS\n",
      "do AUX VBP\n",
      "infringe VERB VB\n",
      "many ADJ JJ\n",
      "of ADP IN\n",
      "the DET DT\n",
      "same ADJ JJ\n",
      "claims NOUN NNS\n",
      "already ADV RB\n",
      "asserted VERB VBN\n",
      "by ADP IN\n",
      "Apple PROPN NNP\n",
      ". PUNCT .\n",
      "\" PUNCT ''\n",
      "\n",
      " SPACE _SP\n",
      "In ADP IN\n",
      "August PROPN NNP\n",
      ", PUNCT ,\n",
      "Samsung PROPN NNP\n",
      "lost VERB VBD\n",
      "a DET DT\n",
      "US PROPN NNP\n",
      "patent NOUN NN\n",
      "case NOUN NN\n",
      "to ADP IN\n",
      "Apple PROPN NNP\n",
      "and CCONJ CC\n",
      "was AUX VBD\n",
      "ordered VERB VBN\n",
      "to PART TO\n",
      "pay VERB VB\n",
      "its PRON PRP$\n",
      "rival ADJ JJ\n",
      "$ SYM $\n",
      "1.05bn NUM CD\n",
      "( PUNCT -LRB-\n",
      "Â£0.66bn NOUN NN\n",
      ") PUNCT -RRB-\n",
      "in ADP IN\n",
      "damages NOUN NNS\n",
      "for ADP IN\n",
      "copying VERB VBG\n",
      "features NOUN NNS\n",
      "of ADP IN\n",
      "the DET DT\n",
      "iPad PROPN NNP\n",
      "and CCONJ CC\n",
      "iPhone PROPN NNP\n",
      "in ADP IN\n",
      "its PRON PRP$\n",
      "Galaxy PROPN NNP\n",
      "range NOUN NN\n",
      "of ADP IN\n",
      "devices NOUN NNS\n",
      ". PUNCT .\n",
      "Samsung PROPN NNP\n",
      ", PUNCT ,\n",
      "which DET WDT\n",
      "is VERB VBZ\n",
      "the DET DT\n",
      "world NOUN NN\n",
      "'s PART POS\n",
      "top ADJ JJ\n",
      "mobile ADJ JJ\n",
      "phone NOUN NN\n",
      "maker NOUN NN\n",
      ", PUNCT ,\n",
      "is AUX VBZ\n",
      "appealing VERB VBG\n",
      "the DET DT\n",
      "ruling NOUN NN\n",
      ". PUNCT .\n",
      "\n",
      " SPACE _SP\n",
      "A DET DT\n",
      "similar ADJ JJ\n",
      "case NOUN NN\n",
      "in ADP IN\n",
      "the DET DT\n",
      "UK PROPN NNP\n",
      "found VERB VBD\n",
      "in ADP IN\n",
      "Samsung PROPN NNP\n",
      "'s PART POS\n",
      "favour NOUN NN\n",
      "and CCONJ CC\n",
      "ordered VERB VBD\n",
      "Apple PROPN NNP\n",
      "to PART TO\n",
      "publish VERB VB\n",
      "an DET DT\n",
      "apology NOUN NN\n",
      "making VERB VBG\n",
      "clear ADJ JJ\n",
      "that SCONJ IN\n",
      "the DET DT\n",
      "South ADJ JJ\n",
      "Korean ADJ JJ\n",
      "firm NOUN NN\n",
      "had AUX VBD\n",
      "not PART RB\n",
      "copied VERB VBN\n",
      "its PRON PRP$\n",
      "iPad PROPN NNP\n",
      "when ADV WRB\n",
      "designing VERB VBG\n",
      "its PRON PRP$\n",
      "own ADJ JJ\n",
      "devices NOUN NNS\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text) # insert code here\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 3] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
    "\n",
    "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
    "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
    "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of purely POS tagging, NLTK peforms much more better as it performs POS tagging by splitting the text into sentences . Whereas NLTk attempts to do POS tagging syntactic tree. We see this in the way that Spacy omits the URL link, which is seen in the NLTK section where it attempts to perform POS tagging with sentence 0, beginning with http."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
    "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at sentence 1, we see no discernable difference in the POS tagging for this sentence by NLTK and Spacy. What we see in more depth is NLTK's attempt to perform POS tagging through sentences, where we see NLTK peforming POS tagging on whole sentences, which can be seen it writes the type of word/sentence by writing the type of phrase which are then put brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
    "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n",
    "* describe differences between the output from NLTK and spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constiuency parsing identifies constituent/whole phrases in a sentence. It does this by performing a parse tree, where parts of a sentence are branched off to their simplest forms in a heirarchical manner. Dependency parsing is the identification the relationships between each word in a sentence. It does this by looking at each word and its neighboring words, and identifying the kind of relationship the sentence has such as a subject-verb relationship or a modifier-noun relationship. In the outputs above, NLTK uses dependency prasing, as we can see in the way that it attempts to look at the relationship of words to each other. Spacy, however, uses constituency parsing. as it breaks words down into its simplest forms without looking at the relationship between each word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
